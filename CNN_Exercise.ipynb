{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sabri2001/DLAV-2023/blob/main/CNN_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb03R-oINjO0"
      },
      "source": [
        "## Convolutional Networks\n",
        "\n",
        "We'll check out how to build a **convolutional network** to classify CIFAR10 images. By using weight sharing - multiple units with the same weights - convolutional layers are able to learn repeated patterns in your data. For example, a unit could learn the pattern for an eye, or a face, or lower level features like edges.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8ZKW4STOlyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe30b35b-bd50-4cec-819a-473bdeee33d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0c3K5CGNjO6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as utils\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpSL2MzAOWnk"
      },
      "outputs": [],
      "source": [
        "label_names = [\n",
        "    'airplane',\n",
        "    'automobile',\n",
        "    'bird',\n",
        "    'cat',\n",
        "    'deer',\n",
        "    'dog',\n",
        "    'frog',\n",
        "    'horse',\n",
        "    'ship',\n",
        "    'truck'\n",
        "]\n",
        "\n",
        "\n",
        "def plot_images(images, cls_true, cls_pred=None):\n",
        "    \"\"\"\n",
        "    Adapted from https://github.com/Hvass-Labs/TensorFlow-Tutorials/\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(3, 3)\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        # plot img\n",
        "        ax.imshow(images[i, :, :, :], interpolation='spline16')\n",
        "\n",
        "        # show true & predicted classes\n",
        "        cls_true_name = label_names[cls_true[i]]\n",
        "        if cls_pred is None:\n",
        "            xlabel = \"{0} ({1})\".format(cls_true_name, cls_true[i])\n",
        "        else:\n",
        "            cls_pred_name = label_names[cls_pred[i]]\n",
        "            xlabel = \"True: {0}\\nPred: {1}\".format(\n",
        "                cls_true_name, cls_pred_name\n",
        "            )\n",
        "        ax.set_xlabel(xlabel)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYaAPNTtNjO8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "7d8f4a5868684dbb80427bba6a42fd2f",
            "33d73d494a114b358c7fc3bf2cc8bfe6",
            "b98323db18c34065af721b5b309e3e39",
            "b4af3dd50aee4a17bf9b9793dd3264fd",
            "96064cfcdebf4db2af9d23c7328d6886",
            "f7f7d13673be4ecf8cf174207268b4d3",
            "0b4498b3c97049f4b09894648e29d8af",
            "e482f61ccbf040b283726b0699e99ac2",
            "3c8a93c920f54a42b2cc960550f40b30",
            "292d2aa292034cf7a108295526e81f45",
            "71117b9d208d471dae490fef5e07d30c"
          ]
        },
        "outputId": "1584ac10-66e0-452f-8f56-41bdc048228e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d8f4a5868684dbb80427bba6a42fd2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "def get_train_valid_loader(data_dir='data',\n",
        "                           batch_size=64,\n",
        "                           augment=False,\n",
        "                           random_seed = 1,\n",
        "                           valid_size=0.02,\n",
        "                           shuffle=True,\n",
        "                           show_sample=False,\n",
        "                           num_workers=4,\n",
        "                           pin_memory=False):\n",
        "    \"\"\"\n",
        "    Utility function for loading and returning train and valid\n",
        "    multi-process iterators over the CIFAR-10 dataset. A sample\n",
        "    9x9 grid of the images can be optionally displayed.\n",
        "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
        "    Params\n",
        "    ------\n",
        "    - data_dir: path directory to the dataset.\n",
        "    - batch_size: how many samples per batch to load.\n",
        "    - augment: whether to apply the data augmentation scheme\n",
        "      mentioned in the paper. Only applied on the train split.\n",
        "    - random_seed: fix seed for reproducibility.\n",
        "    - valid_size: percentage split of the training set used for\n",
        "      the validation set. Should be a float in the range [0, 1].\n",
        "    - shuffle: whether to shuffle the train/validation indices.\n",
        "    - show_sample: plot 9x9 sample grid of the dataset.\n",
        "    - num_workers: number of subprocesses to use when loading the dataset.\n",
        "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
        "      True if using GPU.\n",
        "    Returns\n",
        "    -------\n",
        "    - train_loader: training set iterator.\n",
        "    - valid_loader: validation set iterator.\n",
        "    \"\"\"\n",
        "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
        "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
        "\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010],\n",
        "    )\n",
        "\n",
        "    # define transforms\n",
        "    valid_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "    ])\n",
        "    if augment:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "    else:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "    # load the dataset\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=train_transform,\n",
        "    )\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=valid_transform,\n",
        "    )\n",
        "\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, sampler=train_sampler,\n",
        "        num_workers=num_workers, pin_memory=pin_memory,\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=batch_size, sampler=valid_sampler,\n",
        "        num_workers=num_workers, pin_memory=pin_memory,\n",
        "    )\n",
        "\n",
        "    # visualize some images\n",
        "    if show_sample:\n",
        "        sample_loader = torch.utils.data.DataLoader(\n",
        "            train_dataset, batch_size=9, shuffle=shuffle,\n",
        "            num_workers=num_workers, pin_memory=pin_memory,\n",
        "        )\n",
        "        data_iter = iter(sample_loader)\n",
        "        images, labels = next(data_iter)\n",
        "        X = images.numpy().transpose([0, 2, 3, 1])\n",
        "        plot_images(X, labels)\n",
        "\n",
        "    return (train_loader, valid_loader)\n",
        "\n",
        "trainloader, valloader = get_train_valid_loader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1zuJ67-NjO_"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, n_input_channels=3, n_output=10):\n",
        "        super().__init__()\n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # Define 2 or more different layers of the neural network                      #\n",
        "        ################################################################################\n",
        "        # Trial 1: conv16k3,maxpool2,conv64k3,maxpool2,4096-512-64-10, lr0.01 -> about 42 %\n",
        "        # Trial 2: conv16k3,maxpool2,conv64k3,maxpool2,4096-512-64-10, dropout 0.5, lr0.01 -> about 37 %\n",
        "        # Trial 3: conv16k3,maxpool2,conv64k3,maxpool2,4096-512-64-10, dropout 0.5, lr0.01, weight_decay 0.01 -> about 37 %\n",
        "        # Trial 4: conv16k3,maxpool2,conv64k3,maxpool2,4096-512-64-10, dropout 0.5, lr0.1, weight_decay 0.05 -> about 39 %\n",
        "        # Trial 5: conv16k3,maxpool2,conv64k3,maxpool2,4096-512-64-10, lr0.1, weight_decay 0.05 -> about 39 %\n",
        "        # Trial 5: conv64k2,maxpool2,drop,conv32k2,maxpool2,drop,2048-128-drop-10, lr0.01, weight_decay 0.01 -> about 37% %\n",
        "        self.conv1 = nn.Conv2d(in_channels=n_input_channels, out_channels=64, kernel_size=2, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=2, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
        "        self.fc1 = nn.Linear(2048,128)\n",
        "        self.fc2 = nn.Linear(128,n_output)\n",
        "        ################################################################################\n",
        "        #                              END OF YOUR CODE                                #\n",
        "        ################################################################################\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # Set up the forward pass that the input data will go through.                 #\n",
        "        # A good activation function betweent the layers is a ReLu function.           #\n",
        "        #                                                                              #\n",
        "        # Note that the output of the last convolution layer should be flattened       #\n",
        "        # before being inputted to the fully connected layer. We can flatten           #\n",
        "        # Tensor `x` with `x.view`.                                                    #\n",
        "        ################################################################################\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(x.size(0), -1) # flatten\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "        ################################################################################\n",
        "        #                              END OF YOUR CODE                                #\n",
        "        ################################################################################\n",
        "    \n",
        "    def predict(self, x):\n",
        "        logits = self.forward(x)\n",
        "        return F.softmax(logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AI6ajoIZNjPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8d520b-74d0-45d5-e338-d912576d5390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-da0b1cef854e>:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(logits)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/1.. Loss: 2.3071.. Test accuracy: 0.1285.. 0.1223 s/batch\n",
            "Epoch: 1/1.. Loss: 2.2776.. Test accuracy: 0.1371.. 0.1024 s/batch\n",
            "Epoch: 1/1.. Loss: 2.2237.. Test accuracy: 0.1705.. 0.1005 s/batch\n",
            "Epoch: 1/1.. Loss: 2.2050.. Test accuracy: 0.1732.. 0.1346 s/batch\n",
            "Epoch: 1/1.. Loss: 2.1534.. Test accuracy: 0.2188.. 0.1002 s/batch\n",
            "Epoch: 1/1.. Loss: 2.1457.. Test accuracy: 0.2135.. 0.1007 s/batch\n",
            "Epoch: 1/1.. Loss: 2.0876.. Test accuracy: 0.2436.. 0.1433 s/batch\n",
            "Epoch: 1/1.. Loss: 2.0832.. Test accuracy: 0.2432.. 0.1051 s/batch\n",
            "Epoch: 1/1.. Loss: 2.0759.. Test accuracy: 0.2207.. 0.1483 s/batch\n",
            "Epoch: 1/1.. Loss: 2.0647.. Test accuracy: 0.2480.. 0.1093 s/batch\n",
            "Epoch: 1/1.. Loss: 2.0414.. Test accuracy: 0.2785.. 0.1415 s/batch\n",
            "Epoch: 1/1.. Loss: 2.0349.. Test accuracy: 0.2770.. 0.1016 s/batch\n",
            "Epoch: 1/1.. Loss: 2.0167.. Test accuracy: 0.2684.. 0.1003 s/batch\n",
            "Epoch: 1/1.. Loss: 1.9798.. Test accuracy: 0.2611.. 0.1094 s/batch\n",
            "Epoch: 1/1.. Loss: 1.9918.. Test accuracy: 0.2676.. 0.1346 s/batch\n",
            "Epoch: 1/1.. Loss: 1.9852.. Test accuracy: 0.2850.. 0.0997 s/batch\n",
            "Epoch: 1/1.. Loss: 1.9679.. Test accuracy: 0.3102.. 0.1005 s/batch\n",
            "Epoch: 1/1.. Loss: 1.9797.. Test accuracy: 0.2908.. 0.1188 s/batch\n",
            "Epoch: 1/1.. Loss: 1.9381.. Test accuracy: 0.2824.. 0.1167 s/batch\n",
            "Epoch: 1/1.. Loss: 1.9717.. Test accuracy: 0.3037.. 0.0990 s/batch\n",
            "Epoch: 1/1.. Loss: 1.9710.. Test accuracy: 0.3035.. 0.1002 s/batch\n",
            "Epoch: 1/1.. Loss: 1.9230.. Test accuracy: 0.2986.. 0.1493 s/batch\n",
            "Epoch: 1/1.. Loss: 1.9280.. Test accuracy: 0.3264.. 0.1017 s/batch\n",
            "Epoch: 1/1.. Loss: 1.9424.. Test accuracy: 0.3211.. 0.1002 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8914.. Test accuracy: 0.3168.. 0.1017 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8837.. Test accuracy: 0.3377.. 0.1571 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8905.. Test accuracy: 0.3287.. 0.1016 s/batch\n",
            "Epoch: 1/1.. Loss: 1.9068.. Test accuracy: 0.3434.. 0.1004 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8694.. Test accuracy: 0.3389.. 0.1008 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8877.. Test accuracy: 0.3494.. 0.1601 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8605.. Test accuracy: 0.3488.. 0.1034 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8572.. Test accuracy: 0.3492.. 0.1583 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8884.. Test accuracy: 0.3533.. 0.1459 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8280.. Test accuracy: 0.3389.. 0.1054 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8340.. Test accuracy: 0.3586.. 0.1008 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8303.. Test accuracy: 0.3484.. 0.1000 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8246.. Test accuracy: 0.3426.. 0.1493 s/batch\n",
            "Epoch: 1/1.. Loss: 1.8052.. Test accuracy: 0.3729.. 0.1005 s/batch\n"
          ]
        }
      ],
      "source": [
        "net = ConvNet()\n",
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "# Choose an Optimizer that will be used to minimize the loss function.         #\n",
        "# Choose a critera that measures the loss                                      #\n",
        "################################################################################\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, weight_decay=0.01)  # Choose the optimizer you want and tune its hyperparameter\n",
        "criterion = torch.nn.CrossEntropyLoss()  # the target label is NOT a one-hotted\n",
        "\n",
        "epochs = 1\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 20\n",
        "for e in range(epochs):\n",
        "    start = time.time()\n",
        "    for images, labels in iter(trainloader):\n",
        "        steps += 1\n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # Run the training process                                                     #\n",
        "        #                                                                              #\n",
        "        #                                                                              #\n",
        "        ################################################################################\n",
        "        optimizer.zero_grad() # don't forget!\n",
        "        \n",
        "        output = net(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "   \n",
        "        running_loss += loss.item()\n",
        "  \n",
        "        ################################################################################\n",
        "        #                              END OF YOUR CODE                                #\n",
        "        ################################################################################\n",
        "\n",
        "        # QUESTION: why the heck twice...\n",
        "        # ################################################################################\n",
        "        # # TODO:                                                                        #\n",
        "        # # Run the training process                                                     #\n",
        "        # #                                                                              #\n",
        "        # # HINT: Calculate the gradient and move one step further                       #\n",
        "        # ################################################################################\n",
        "        # pass\n",
        "        # ################################################################################\n",
        "        # #                              END OF YOUR CODE                                #\n",
        "        # ################################################################################\n",
        "\n",
        "        if steps % print_every == 0:\n",
        "            stop = time.time()\n",
        "            # Test accuracy\n",
        "            accuracy = 0\n",
        "            for ii, (images, labels) in enumerate(valloader):\n",
        "                \n",
        "                ################################################################################\n",
        "                # TODO:                                                                        #\n",
        "                # Calculate the accuracy                                                       #\n",
        "                ################################################################################                \n",
        "                predicted = net.predict(images).data\n",
        "                equality = (labels == predicted.max(1)[1])\n",
        "                accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
        "                ################################################################################\n",
        "                #                              END OF YOUR CODE                                #\n",
        "                ################################################################################\n",
        "            \n",
        "            print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
        "                  \"Loss: {:.4f}..\".format(running_loss/print_every),\n",
        "                  \"Test accuracy: {:.4f}..\".format(accuracy/(ii+1)),\n",
        "                  \"{:.4f} s/batch\".format((stop - start)/print_every)\n",
        "                 )\n",
        "            running_loss = 0\n",
        "            start = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUqGBbcpNjPB"
      },
      "source": [
        "Save best trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BKFS7ALNjPB"
      },
      "outputs": [],
      "source": [
        "## You should be familiar with how to save a pytorch model (Make sure to save the model in your Drive)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d8f4a5868684dbb80427bba6a42fd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33d73d494a114b358c7fc3bf2cc8bfe6",
              "IPY_MODEL_b98323db18c34065af721b5b309e3e39",
              "IPY_MODEL_b4af3dd50aee4a17bf9b9793dd3264fd"
            ],
            "layout": "IPY_MODEL_96064cfcdebf4db2af9d23c7328d6886"
          }
        },
        "33d73d494a114b358c7fc3bf2cc8bfe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7f7d13673be4ecf8cf174207268b4d3",
            "placeholder": "​",
            "style": "IPY_MODEL_0b4498b3c97049f4b09894648e29d8af",
            "value": "100%"
          }
        },
        "b98323db18c34065af721b5b309e3e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e482f61ccbf040b283726b0699e99ac2",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c8a93c920f54a42b2cc960550f40b30",
            "value": 170498071
          }
        },
        "b4af3dd50aee4a17bf9b9793dd3264fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_292d2aa292034cf7a108295526e81f45",
            "placeholder": "​",
            "style": "IPY_MODEL_71117b9d208d471dae490fef5e07d30c",
            "value": " 170498071/170498071 [00:10&lt;00:00, 16618320.12it/s]"
          }
        },
        "96064cfcdebf4db2af9d23c7328d6886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7f7d13673be4ecf8cf174207268b4d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b4498b3c97049f4b09894648e29d8af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e482f61ccbf040b283726b0699e99ac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c8a93c920f54a42b2cc960550f40b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "292d2aa292034cf7a108295526e81f45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71117b9d208d471dae490fef5e07d30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}